
# ğŸ¤ Assistente de Voz MultilÃ­ngue com Python, Whisper e ChatGPT

Este projeto implementa um **assistente de voz multilÃ­ngue** que combina **gravaÃ§Ã£o de Ã¡udio**, **transcriÃ§Ã£o automÃ¡tica**, **geraÃ§Ã£o de respostas inteligentes** e **sÃ­ntese de voz**.  
Ele foi desenvolvido em **Python** com suporte de **JavaScript**, **Whisper (OpenAI)**, **ChatGPT** e **gTTS** com apoio da DIO e Bradesco

---

## ğŸš€ Funcionalidades
- ğŸ™ï¸ **GravaÃ§Ã£o de Ã¡udio** diretamente no navegador via `MediaStream Recording API`.
- ğŸ§  **Reconhecimento de fala** com o modelo Whisper da OpenAI.
- ğŸ’¬ **IntegraÃ§Ã£o com ChatGPT** para respostas inteligentes.
- ğŸ”Š **SÃ­ntese de voz** com gTTS para reproduzir a resposta em Ã¡udio.
- ğŸŒ **Suporte multilÃ­ngue** configurÃ¡vel pela variÃ¡vel `language`.

---

## ğŸ“‚ Estrutura do Projeto
1. **GravaÃ§Ã£o de Ãudio (Python + JS)**  
   - Captura Ã¡udio do microfone.  
   - Converte para `.wav`.  
   - Salva no diretÃ³rio `/content/` do Google Colab.  

2. **Reconhecimento de Fala (Whisper)**  
   - InstalaÃ§Ã£o do Whisper via `pip`.  
   - Carregamento do modelo (`small`, mas pode ser alterado).  
   - TranscriÃ§Ã£o automÃ¡tica do Ã¡udio para texto.  

3. **IntegraÃ§Ã£o com ChatGPT**  
   - ConfiguraÃ§Ã£o da API Key da OpenAI.  
   - Envio da transcriÃ§Ã£o para o ChatGPT.  
   - Recebimento da resposta textual.  

4. **SÃ­ntese de Voz (gTTS)**  
   - ConversÃ£o da resposta em Ã¡udio.  
   - ReproduÃ§Ã£o do Ã¡udio diretamente no Colab.  

---

## ğŸ› ï¸ Requisitos
- Python 3.x  
- Google Colab (ou ambiente compatÃ­vel)  
- Bibliotecas:  
  - `IPython`  
  - `google.colab`  
  - `base64`  
  - `whisper`  
  - `gtts`  

---

## ğŸ“Œ Como Usar
1. Clone ou copie o cÃ³digo para o Google Colab.  
2. Execute as cÃ©lulas em ordem:  
   - GravaÃ§Ã£o de Ã¡udio.  
   - TranscriÃ§Ã£o com Whisper.  
   - IntegraÃ§Ã£o com ChatGPT.  
   - SÃ­ntese de voz com gTTS.  
3. Configure a variÃ¡vel `language` para o idioma desejado (`'pt'`, `'en'`, `'es'`, etc.).  
4. Insira sua **API Key da OpenAI** em:  
   ```python
   os.environ['OPENAI_API_KEY'] = 'SUA_API_KEY_AQUI'
   ```

---

## ğŸŒ Idiomas Suportados
- PortuguÃªs (`pt`)  
- InglÃªs (`en`)  
- Espanhol (`es`)  
- FrancÃªs (`fr`)  
- AlemÃ£o (`de`)  
- E muitos outros suportados pelo Whisper e gTTS.  

---

## ğŸ“– ReferÃªncias
- [Whisper GitHub](https://github.com/openai/whisper)  
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference/introduction)  
- [gTTS Documentation](https://pypi.org/project/gTTS/)  
- [MediaStream Recording API](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API)  

---

## ğŸ’¡ PossÃ­veis Melhorias
- Adicionar interface grÃ¡fica.  
- Suporte offline para sÃ­ntese de voz.  
- IntegraÃ§Ã£o com outros modelos de IA.  
- Exportar histÃ³rico de conversas.  

---

## ğŸ“œ LicenÃ§a
Este projeto Ã© de uso livre para fins educacionais e experimentais.  

---

ğŸ‘‰ VocÃª gostaria que eu tambÃ©m criasse um **exemplo de uso passo a passo** (com cÃ³digo simplificado) para colocar no README, mostrando a execuÃ§Ã£o completa em Colab? Isso deixaria o projeto ainda mais acessÃ­vel para iniciantes.
